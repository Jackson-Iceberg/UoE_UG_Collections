# Foundations-of-Natural-Language-Processing
### Course Outline

This course covers some of the linguistic and algorithmic foundations of natural language processing (NLP). It builds on algorithmic and data science concepts developed in second year courses, applying these to NLP problems. It also equips students for more advanced NLP courses in year 4. The course is strongly empirical, using corpus data to illustrate both core linguistic concepts and algorithms, including language modelling, part of speech tagging, syntactic processing, the syntax-semantics interface, and aspects of semantic and pragmatic processing. The theoretical study of linguistic concepts and the application of algorithms to corpora in the empirical analysis of those concepts will be interleaved throughout the course.

An indicative list of topics to be covered include the following (although they won't be presented in this order):

1. Lexicon and lexical processing:
   \* morphology
   \* language modeling
   \* hidden Markov Models and associated algorithms
   \* part of speech tagging (e.g., for a language other than English) to illustrate HMMs
   \* smoothing
   \* text classification

2. Syntax and syntactic processing:
   \* the Chomsky hierarchy
   \* syntactic concepts: constituency (and tests for it), subcategorization, bounded and unbounded dependencies, feature representations
   \* context-free grammars
   \* lexicalized grammar formalisms (e.g., dependency grammar)
   \* chart parsing and dependency parsing (eg, shift-reduce parsing)
   \* treebanks: lexicalized grammars and corpus annotation
   \* statistical parsing

3. Semantics and semantic processing:
   \* word senses: regular polysemy and the structured lexicon; distributional models; word embeddings (including biases found)
   \* compositionality, constructing a formal semantic representation from a (disambiguated) sentential syntactic analysis.
   \* predicate argument structure
   \* word sense disambiguation
   \* semantic role labelling
   \* pragmatic phenomena in discourse and dialogue, including anaphora, presuppositions, implicatures and coherence relations.
   \* labelled corpora addressing word senses (e.g., Brown), semantic roles (e.g., Propbank, SemCor), discourse information (e.g., PDTB, STAC, RST Treebank).

4. Data and evaluation (interspersed throughout other topics):
   \* cross-linguistic similarities and differences
   \* commonly used datasets
   \* annotation methods and issues (e.g., crowdsourcing, inter-annotator agreement)
   \* evaluation methods and issues (e.g., standard metrics, baselines)
   \* effects of biases in data



### Learning Outcomes

On successful completion of this course:

1. Given an appropriate NLP problem, students should be able to select a corpus and an annotation scheme for the problem and justify the choice over other candidates.
2. Students should also be able to identify suitable evaluation measures for the problem and provide a written explanation of the role of annotated corpora in natural language processing.
3. Given one of the main linguistic issues relevant to NLP (including the representation and induction of syntactic knowledge, and the modelling of lexical and semantic information, and the syntax-semantics interface), students should be able to construct an example of the issue and provide an explanation of how their example illustrates the issue in general.
4. Given an example of one of the main linguistic issues identified above, students should be able to classify it as belonging to that issue and relate the example to the issue in general.
5. Given an NLP problem, students should be able to analyse, assess and justify which algorithms are most appropriate for solving the problem, based on an understanding of fundamental algorithms such as Viterbi algorithm, inside-outside, chart-based parsing and generation.



Coursework at University of Edinburgh, UG4

CW1: 76/100	

CW2: 90/100	

overall: 83% (A2)
